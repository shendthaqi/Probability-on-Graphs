\section{Entropy, its subadditivity and the log-Sobolev inequality}


\begin{defn}[Entropy]
    For a non-negative random variable $X\geq 0$, we define the entropy as 
    $$\Ent{X}:= \EE[X\ln(X)]- \EE[X]\ln(\EE[X])$$
\end{defn}


\begin{remark}[Properties of entropy]  
    We have 
    \begin{enumerate}
        \item $x\ln(x) \geq e^{-1}$ for $x\geq 0$
        \item Convexity: $\EE[X \ln(X)] \geq \EE[X] \ln(\EE[X])$
        \item $\Ent{X}=0 \iff X = \operatorname{const.}$, $\PP$-a.s.
        \item $\Ent{\alpha X}= \alpha \Ent{X}$ for $\alpha \geq 0$
    \end{enumerate}
\end{remark}


\begin{thm}[Duality of entropy]
    For any random variable $X\geq 0$, we have 
    \begin{align*}
        \Ent{X} &= \sup \cub{\EE[UX] \fil \EE[e^U]\leq 1} \\
        &= \sup \cub{ \EE[X(\ln(Y) - \ln(\EE[Y]))] \fil Y>0, \EE[Y]<\infty}
    \end{align*}
    Moreover, if $U\in \LLL^1$ and for all $X\geq 0$ with $\Ent{X}\leq 1$, we have $\EE[UX]\leq 1$, then $\EE[e^{U}]\leq 1$.
\end{thm}


\begin{thm}[Subadditivity of entropy]
    Let $\XN$ be independent random variables. For $f:\RR^{N}\to [0,\infty)$ measurable, we have 
    $$\Ent{f(\XN)} \leq \EE\left( \sumn \Ent_n f(\XN) \right)$$
    where $\Ent_n$ describes the entropy wrt the probability measure 
    $$\EE_n [f(\XN)] := \EE[f(\XN) \vert X_1,\dots, X_{n-1},X_{n+1}, \dots, X_N]$$
\end{thm}


\begin{defn}[log-Sobolev inequality property]
    A random variable $X$ satisfies a log-Sobolev inequality (LSI) with some constant $\alpha$ if for smooth $f$ we have 
    $$\Ent{f(X)^2} \leq \alpha \EE[\abs{\nabla f(X)}^2]$$
\end{defn}


\begin{exm}[Rademacher random variable]
    Let $X$ be such that $\PP(X=1)= \PP(X=-1)=\frac{1}{2}$. Then for any $f:\cub{-1,1}\to \RR$: 
    $$\Ent{f(X)^2} \leq 2\VV[f]$$
    Note that 
    \begin{align*}
        \VV[f] &= \frac{1}{2}\EE[(f(X)-f(X'))^2] \\
        &= \frac{1}{4}(f(1)-f(-1))^2 \\
        &= \frac{1}{4}\EE[(f(1)-f(-1))^2]
    \end{align*}
\end{exm}


\begin{thm}[Tensorization of LSI]
    Let $\XN$ be independent random variables satisfying LSI with $\alpha$. Then $X=(\XN)$ satisfies LSI with $\alpha$.
\end{thm}


\begin{thm}[Federbush-Gross]
    Let $\XN$ be independent with law $\NNN(0,1)$. Then $X=(\XN)$ satisfies a LSI with parameter 2, i.e. 
    $$\Ent{f(X)^2} \leq 2 \EE \abs{\nabla f(X)}^2$$
\end{thm}


\begin{remark}[Outlook of Bahry-Emry condition]
    If $U:\RR^N \to [0,\infty)$ is twice differentiable with $$\operatorname{Hess }U \geq c\ONE \quad \trm{for some }c>0$$
    then $\mu(\dd{x}=e^{-U(x)}\dd{x} / \int e^{-U(x)}\dd{x}$ satisfies a LSI with constant $2/c$.
\end{remark}