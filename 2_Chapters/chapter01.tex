\section{Basics of graph theory}

\begin{defn}[Graph]
    A \emph{graph} \(G=(V,E)\) is a consists of 
    \begin{enumerate}[1)]
      \item \(V \neq \emptyset\);
      \item \(E \ssq \set*{ \{u,v\}; u,v \in V}\).
    \end{enumerate}
    We call elements of $V$ \emph{vertices} or \emph{nodes} and elements of \(E\) \emph{edges} or \emph{bonds}. We write $v\sim u$ if \(\{u,v\}\in E\). A graph $G=(V,E)$ is called \emph{network} if for $e=\{u,v\} \in V$, we assign a weight $c(u,v)>0$. For $v \in V$, we set $c(v)=\sum_{u \sim v}c(u,v)$. We further define 
    \begin{itemize}
      \item A vertex $v$ is called \emph{incident} to an edge $e$ if $v \in e$;
      \item the \emph{degree} of a vertex $v$ is the number of edges incident to it: \(\operatorname{deg}v= \abs{\set*{\{u,v\}\in E; u\sim v}} \);
      \item the graph $G$ is called \emph{locally finite} if for all $v \in V$, \(\operatorname{deg}v<\infty\);
      \item for $u,v \in V$, $\pi =(x_1,\dots,x_N)$ is called a \emph{path} from $u$ to $v$ if $v=x_1,\, x_N=v$ and $ \{x_{n-1},x_n\} \in E$; 
      \item a path from $u$ to $u$ is called a \emph{cycle};
      \item a graph $G$ is called \emph{connected} if for any $u,v \in V$ there is a finite path from $u$ to $v$.
    \end{itemize}
    
\end{defn}

ede


\begin{defn}[Product of graphs]
    Let $G_1, G_2$ be graphs. We define  
    \begin{align*} G_1 \boxtimes G_2:= &(V_1\times V_2, \\
      & \set*{\left(\left(x_1,y_1\right),(x_2,y_2)\right); \text{either }\left(x_1=x_2 ,\,(y_1,y_2)\in E_2\right) \text{ or } \left(y_1=y_2,\,(x_1,x_2)\in E_1\right)})
    \end{align*}

    as the \emph{product} of $G_1$ and \(G_2\).
\end{defn}





\begin{defn}[Vertex simple and edge simple paths]
  Let $G$ be a graph. A \emph{path} is a (possibly infinite) sequence of vertices $v_1,v_2,\dots$ such that $(v_n,v_{n+1})\in E$. 
  \begin{enumerate}[1)]
    \item If a path does not visit any vertex more that once, it is called a \emph{vertex simple path}.
    \item If a path does not visit any edge more than once, it is called an \emph{edge simple path}.
  \end{enumerate}
\end{defn}


\begin{defn}[Network]
  A \emph{network} is a graph $G$ combined with a function $c:E\to [0,\infty)$ with if $c(u,v)=0$ if $(v,u)\notin E$. We call a network connected if $(V, \set*{e\in E; c(e)>0})$ is connected. A network is locally finite if for any \(v\in V\), we have \(c(v) = \sum_{u\sim v}c(u,v)<\infty\).  
\end{defn}


\begin{lem}[Example]
  $V=\ZZ$, $E= \cub{(v,u) \fil u\neq v\in V}$ with $c(v,u)=\frac{1}{\abs{u-v}^2}$.
\end{lem}


\begin{defn}[Cycle]
  A cycle is a path starting and ending in the same point. A cycle is simple if the only vertex appearing more than once is the first (and last) vertex.
\end{defn}


\begin{defn}[Induced graphs and networks]
  Let $G=(V,E)$ be a graph and let \(K\ssq V\). The induced graph is the graph \(G_K=(K, \cub{e\in E \fil e \ssq K})\). The induced network is defined similarly. 
\end{defn}

\begin{defn}[Connected component]
    Let $G$ be a graph a graph or a network. A connected component is a set $K$ of vertices such that $G_K$ is connected, but for every $K\subsetneq H $, $G_H$ is not connected.
\end{defn}

\begin{defn}[Contraction of graphs]
  Let $G=(V,E,c)$ be a graph (or network) and let $K\ssq G$. The connected graph (or network) $G/K$ is the graph $(V\setminus \cup \cub{z}, \cub{e \in E \fil e \ssq V\setminus K} \cup \cub{(v,z) \fil v \notin K, \exists u \in K: (v,u) \in E})$. For all $u,v \notin K$, take conductance \(c'(v,u) = c(v,u)\) for $v\notin K$ take $c(v,u)=\sum_{u\in K} c(v,u)$.
\end{defn}


\begin{defn}[Forest and tree]
    A forest is a graph with no (simple) cycles. A tree is a connected forest.
\end{defn}


\begin{remark}
    A contraction of an edge lets it "disappear" in a sense that the vertices are merged.
\end{remark}


\begin{defn}[Homomorphisms]
    Let $G_1,G_2$ be graphs. Let \(\phi: V_1 \to V_2\) be a function.
    \begin{enumerate}
      \item \(\phi\) is called a \emph{homomorphism} if for all $(u,v) \in E_1$, we have that \((\phi(u), \phi(v)) \in E_2\);
      \item \(\phi \) is called an \emph{isomorphism} if \(\phi \) is bijective, and \(\phi , {\phi }^{-1}\) are homomorphisms. In this case, \(G_1, G_2\) are called \emph{isomorpic};
      \item \(\phi \) is called an \emph{automorphism} if \(\phi \) is an isomorphism with \(G_1=G_2\).
    \end{enumerate}
\end{defn}

\begin{defn}[Transitivity]
    A graph $G=(V,E)$ is called (vertex) transitive if for all \(v,u\in V\) there is an automorhpism \(\phi\) such that \(\phi(v)=u\). $G$ is called edge transitive if for every $e_1,e_2 \in E$ there is an automorphism $\phi(e_1)=e_2$.
\end{defn}

\begin{remark}
    There are graphs that are vertex transitive but not edge transitive.
\end{remark}

\begin{remark}
  Good source of example for transitive graphs: Let $G$ be a graph, and let $Y \ssq G\setminus\cub{\trm{unit}}$. Take the graph $V=G$ and $(u,v) \in E$ if there is $y\in Y$ such that $u=yv$ or $v=yu$.
\end{remark}


\subsection{Random walks on networks}

\begin{defn}[Simple rnadom walk on networks]
Let $G=(V,E,c)$ be a network and assume that $G$ is locally finite. The simple random walk on $G$ is the (discrete time) Markov chain with transition matrix
\[\Pi(x,y) = \frac{c(x,y)}{\sum_z c(x,z)} \cdot \ONE\left[\sum_z c(x,z) >0\right] + 1 \cdot \ONE\left[\sum_z c(x,z)=0\right] \]
A random walk on a locally finite graph $G=(V,E)$ is a random walk on the network $(V,E,1)$.
\end{defn}


\begin{remark}
    Question: Does \(\mathbb{Z}^d\) have a transient subgraph?\\
    Answer: No, every subgraph of a recurrent graph is recurrent. \\ 
    The main tool to provide the proof for the answer is based on the connection between the random walk and electrical networks.
\end{remark}


\begin{lem}
  Let $G=(V,E,c)$ be a finite connected network. For every $x\in V$, let \(p^x\) be the distribution of the random walk on $G$ started on $x$. Let $a,z \in V$. Let $\tau_a$ ($\tau_z$) be the first time hitting $a$ ($z$), and let $\tau_{a,z}$ be first time hitting either of them. Then, $\tau_a,\tau_z,\tau_{a,z}< \infty$.
\end{lem}


\begin{fact}
  Let $G=(V,E,c)$ be a finite connected network. We consider the simple random walk defined as above. Then, every state $x$ is recurrent. We have $\PP_x(\tau_a < \infty)= \mathbb{P}_x(\tau_z<\infty)=1$.
\end{fact}
\begin{proof}
For every $x$, let $\gamma_x$ be a path from $x$ to $a$. Let $h_x$ be the probability that the random walk takes the path $\gamma_x$ immediately starting in $x$. Let $h= \min_{x\in V}h_x>0$. Let $\mathcal{F}_n ) = \sigma(X_1, \dots, X_N), \, \mathcal{F}=\sigma(X_1, X_2, \dots)$. Then, $\set*{\tau_a < \infty } \in \FFF$. By Kolmogorov's 0-1-law, $\mathbb{P}_x \setround*{\tau_a<\infty ; \FFF} \in \set*{0,1 }$. We have \(\mathbb{P}_x \setround*{\tau_a < \infty  ; \mathcal{F}} = \lim_{n \to \infty} \mathbb{P}_x \setround*{\tau_a < \infty ; \mathcal{F}_n}\). We have \(\mathbb{P}_x \setround*{\tau_a < \infty ;\mathcal{F}_n} \geq h \). Thus, \(\mathbb{P}_x \setround*{\tau_a <\infty  ;\mathcal{F}}\geq h\). It follows from the 0-1-law, $\mathbb{P}_x \setround*{ \tau_a < \infty ;\mathcal{F}}=1$ and thus \(\mathbb{P}_x(\tau_a < \infty) = \mathbb{E} \left[\mathbb{P}_x \setround*{\tau_a <\infty; \mathcal{F}}\right]\). 
\end{proof}



\begin{defn}[Voltage function]
  The voltage function is defined as \[\mathcal{U}: V \to \RR, x \mapsto \mathcal{U}(x):=\mathbb{P}_x(\tau_{a,z}=\tau_a)\]
\end{defn}


\begin{lem}[Properties of the voltage function]
  Let $\mathcal{U}: V \myxrightarrow[]{} \mathbb{R}, x \mapsto \mathbb{P}_x(\tau_{a,z}=\tau_a)$ be the voltage function. Then, the following statements hold:
  \begin{enumerate}
      \item \(\mathcal{U}(a)=1\);
      \item \(\mathcal{U}(z)=0\);
      \item For $x\neq a,z$, we have \[\mathcal{U}(x) = \sum_{y\in V}^{} \mathbb{P}_x(X_1=y) \mathcal{U}(y) = \sum_{y\in V}^{} \frac{c(x,y)}{\sum_{z\in V} c(x,z) }\mathcal{U}(y) = \sum_{y\in V}^{} c(x,y) \frac{\mathcal{U}(y)}{c(x)}\] (harmonicity)
  \end{enumerate}
\end{lem}
\begin{proof}
    To show the harmonicity, we use the Markov property. Since \(x \neq a,z\), \(p^x(\tau_a\geq 1)=1\). The Markov property implies 
    \begin{align*}
      p^x(\tau_a \leq \tau_z) &= \mathbb{E}_x \left[ p^x(\tau_a < \tau_z)\right] \\
                              &= \sum_y p^x(X_1=y)\cdot p^y(\tau_a < \tau_z) \\
                              &= \sum_y p^x(X_1=y) \cdot \mathcal{U}(y)
    \end{align*}    
\end{proof}

\begin{lem}[Uniqueness of voltage function]
    The voltage function $\mathcal{U}$ is the only function satisfying the properties above.
\end{lem}
\begin{proof}
    Assume $\mathcal{U}_1,\mathcal{U}_2$ satisfy the properties of the voltage function. We show $h \equiv \mathcal{U}_1-\mathcal{U}_2=0$. 
    \begin{enumerate}
      \item By properties 1 and 2, $h(a)=h(z)=0$. 
      \item For $x\neq a,z$, we have \(h(x) = \sum_y \frac{c(x,y)}{c(x)} h(y)\) ($h(x)$ is a weighted average over its neighbors). Assume $h(x) \neq 0$. We assume \OE $h(x) >0$. Let \(M=\max_{}\set*{h(x); x\in V}>0\). Let \(H= \set*{x; h(x)=M}\). Note that $a,z \notin H$. Let $x$ be an element of $H$ with a neighbor $w$ outside of  $H$. Then, the following are true
        \begin{enumerate}
            \item $x\in H$, thus $h(x)=M$.
            \item 
              \begin{align*}
                h(x)  &=\sum_y \frac{c(x,y)}{c(x)} h(y) \\
                     &=\frac{c(x,w)}{c(x)}h(w) + \sum_{y\neq w} \frac{c(x,y)}{c(x)}h(y) \\
                     &\leq h(w) \frac{c(x,w)}{c(x)} + M \sum_{y\neq w} \frac{c(x,y)}{c(x)} \\
                     & h(w) \frac{c(x,w)}{c(x)} + M \left(1-\frac{c(x,w)}{c(x)}\right) \\
                     &=M + \underbrace{ \left(h(w)-M\right)}_{<0}\cdot \underbrace{\frac{c(x,w)}{c(x)}}_{>0} < M
              \end{align*}
              
        \end{enumerate}
        This is a contradiction to $h \neq 0$.
    \end{enumerate}
\end{proof}

\begin{remark}
    The proof is similar to the proof of uniqueness of the solution to the Dirichlet problem.
\end{remark}

\begin{remark}
    In the theory of electrical networks, the (physical) voltage function satisfies the same three properties (up to normalization of the boundary conditions). Therefore, everything that is known about physical electrical networks has the potential of being useful in the understanding of random walks on networks.
\end{remark}


\begin{defn}[Resistance]
    For an edge $e$, we define its resistance as
    \[r(e)= \frac{1}{e}\]
\end{defn}


\subsection{Currents and flows}

\begin{defn}[Current]
    Let $e=(x,y) \in E$. For every \(x,y\) we define the current as
    \[I(x,y) = \frac{\mathcal{U}(x)-\mathcal{U}(y)}{r(x,y} = \left(\mathcal{U}(x)-\mathcal{U}(y)\right) c(x,y)\]
\end{defn}


\begin{lem}[Properties of the current]
    Let $I$ be the current. Then, the following statements hold:
    \begin{enumerate}
      \item \(I(x,y) = -I(y,x)\) (Antisymmetry) 
      \item For $x\neq a,z$, $\sum_{y\neq x} I(x,y) = 0$ (Kirchhof's node law)
      \item For a cycle ${x}_{0} , \dots , {x}_{N}=x_0 $, then \(\sum_{n=1}^{N} I(x_{n-1},x_n)r(x_{n-1},x_n) = 0\) (Kirchhof's circuit law)
    \end{enumerate}
    
\end{lem}

\begin{proof} \,
    \begin{enumerate}
      \item follows from $c(x,y)=c(y,x)$.
      \item Notice that 
        \begin{align*}
          \sum_{y\neq x}I(x,y) &= \sum_{y\neq x}c(x,y) \left(v(x)-v(y)\right) \\
                               &=v(x)\sum_{y\neq x}c(x,y) - \sum_{y\neq x}c(x,y)v(y) \\
                               &=v(x)c(x) - c(x)\sum_{y\neq x}\frac{c(x,y)}{c(x)}v(y) \\
                               &=0
        \end{align*}
        where we used the harmonity of $v$.
      \item By definition of $I$, we have $(I\cdot r)(x,y)=v(x)-v(y)$. Thus, we have 
        \begin{align*}
          \sum_{n=1}^{N} I(x_{n-1,x_n)r(x_{n-1},x_n)} = \sum_{n=1}^{N} v(x_{n-1})-v(x_n) = 0
        \end{align*}        
    \end{enumerate}
\end{proof}


\begin{defn}[Flow]
    A flow is a function \(F: V^2\to \mathbb{R}\), such that 
    \begin{enumerate}
      \item \(F(x,y) = -F(y,x)\)
      \item If $x \nsim y$, then \(F(x,y)=0\)
      \item For all \(x\neq a,z\), we have \(\sum_{y\neq x} F(x,y)=0\) (Kirchhof's node law)
    \end{enumerate}    
\end{defn}


\begin{defn}[Total current]
    The total current in a network is defined as 
    \[\sum_{x\neq a} I(a,x)  =\sum_{x\neq z} I(x,z)\]
\end{defn}

\begin{proof}
    We prove equality for the two descriptions of total current.
    \begin{align*}
      \sum_{x\neq a} I(a,x) - \sum_{x \neq z} I(x,z) &= \sum_{x \neq a}^{} I(a,x) + \sum_{x \neq z}^{} I(z,x) + \underbrace{\sum_{y \neq a,z} \sum_{x \neq y} I(y,x)}_{=0} \\
                                                     & \stackrel{(\mathrm{I})}{=} \sum_{y} \sum_{x \neq y} I(y,x) \\
                                                     &=\sum_{\{x,y\} \ssq V} I(x,y) + I(y,x) \\
                                                     &= 0
    \end{align*}
\end{proof}


\begin{defn}[Effective resistance]
    The effective resistance in a network is defined as 
    \[R_{\mathrm{eff}}(a,z) = \frac{1}{\mathrm{total\;current}}\]
    Similarly, we denote
    \[c_{\mathrm{eff}}(a,z) = \mathrm{total\;current}\]
\end{defn}


\begin{nota}[Stopping times]
    We use the following notation for stopping times 
    \begin{align*}
      \tau_x  &= \inf \set*{t\geq0; X_t=x} \\
      \sigma_x &= \inf \set*{t\geq0; X_t\neq x} \\
      \eta_x^0 &=0 \\
      \eta_x &= \inf \set*{t>0; X_t=x} \\
      \eta_x^{n+1} &= \inf \set*{t > \eta_x^n; X_t=x }
    \end{align*}
    Notice that $\tau_x \neq \eta_x$ under $\PP_x$ and $\tau_x=\eta_x$ under $\PP_y$ for $y\neq x$.
\end{nota}

\begin{lem}[$n$-th return time of Markov chains]
    Notice that if $X$ is a Markov chain, then we have 
    \[\eta_x^{n+1} = (\tau_x \circ \theta_{\sigma_x} + \sigma_x) \circ \theta_{\eta_{x}^n} + \eta_{x}^n \]
\end{lem}


\begin{thm}[]

    Let \(G=(V,E,c)\) be a connected network, \(a\neq z \in V\). Let \(\tau_x:=\inf_{} \set*{n\geq 0 ; X_n=x}\) and \(\eta_{x}=\inf_{} \set*{n\geq 1 ; X_n=1}\). Then, 
    \[\mathbb{P}_a \left(\tau_z < \eta_a\right) = \frac{c_{\mathrm{eff}}(a,z)}{c(a)}\]
\end{thm}

\begin{proof}
    We have that 
    \begin{align*}
      \mathbb{P}_a(\tau_z < \eta_a) &= \sum_x \mathbb{P}_a(X_1=x)\mathbb{P}_x(\tau_z < \eta_a) \\
                                    &=\sum_x \frac{c(a,x)}{c(a)} \cdot (\underbrace{1}_{v(a)}-\underbrace{\mathbb{P}_x(\tau_a-\tau_z)}_{v(x)}) \\
                                    &=\frac{1}{c(a)} \sum_x c(a,x) \left(v(a)-v(x)\right) \\
                                    &=\frac{1}{c(a)}\sum_x I(a,x) \\
                                    &=\frac{c_{\mathrm{eff}}(a,z)}{c(a)}
    \end{align*}
    
\end{proof}


\begin{thm}[Commute time formula]
    We have that 
    \[\mathbb{E}_a \left[\tau_z\right] + \mathbb{E}_z \left[\tau_a\right] = 2 R_{\mathrm{eff}}(a,z) + \sum_{e\in E}c(e)\]
\end{thm}

\begin{proof} We first provide facts about Markov chains.
    \begin{enumerate}
      \item Every Markov chain on a finite state space has an invariant distribution. If the Markov chain is a random walk on a finite connected network, then 
        \[\mu(x)=\frac{c(x)}{2 \sum_{e\in E}c(e)}\]
        is the unique invariant distribution, since 
        \begin{enumerate}[i)]
          \item \(\mu \) is a distribution: \(\mu(x)\geq 0\) holds since $c\geq 0$, and 
            \begin{align*}\sum_x \mu(x) &= \frac{1}{2 \sum_{e\in E} c(e)}\sum_x \left(\sum_y c(x,y)\right) \\
              &= \frac{1}{2 \sum_{e\in E}c(e)} \cdot 2 \sum_{e\in E} c(e) \\
              &=1
            \end{align*}
          \item \(\mu\) is invariant: Let $X=_d \mu$, then for every $x$
            \begin{align*}
              \mathbb{P}_{\mu }&= \sum_y \mathbb{P}_{\mu }(X_0=y) \mathbb{P}_{\mu } \setround*{X_1 ;X_0=y} \\
                               &= \sum_y \mu(y) \cdot \frac{c(x,y)}{c(y)} \\
                               &=\frac{1}{2 \sum_e c(e)} \sum_y c(y) \frac{c(x,y)}{c(y)} \\
                               &=\frac{1}{2 \sum_e c(e)}c(x) \\
                               &= \mu(x)
            \end{align*}
        \end{enumerate}
      \item \(\mathbb{E}_x[\eta_x] = \frac{1}{\mu(x)}\). We sketch the proof of this claim: Let \(\mu \) be stationary and invariant distribution, i.e. \(X_n =_d \mu\) for all $n\geq 0$. Then, for large $N$, $\mu(x)\cdot N$ is approximately the number of times we are at $x$. Thus, for the average distance between appearances of $x$, we have  \(\EE[\eta_x^{n+1}-\eta_x^n]=\frac{1}{\mu(x)}\). This can be shown using the Markov property to derive $\eta_x^1=_d \eta_x^{n+1}- \eta_x^n$ and using the Law of Large Numbers. 
      \item Let \(\eta_a^1, \eta_a^2, \dots\) be the consecutive return times to \(a\). Let \(m:=\inf_{} \set*{k\geq 0; \eta_a^{k-1}< \tau_z < \eta_a^k}\). Then
        \begin{align*}
          \mathbb{E}_{a}[\tau_z] + \mathbb{E}_{z}[\tau_a] &= \mathbb{E}_{a}[\eta_a^m] \\
                                                          &=\mathbb{E}_{a}[\eta_a^{m-1}]+ \mathbb{E}_a[\eta_a^m - \eta_a^{m-1}] \\
                                                          &=\mathbb{E}_a[m-1]\mathbb{E} \setsquared*{\eta_a^1 ; \eta_{a}^1 < \tau_z} + \mathbb{E}_{a} \setsquared*{\eta_a^1 ;\tau_z < \eta_a^n} \\ &= \mathbb{E}[\mathrm{Geom}(\mathbb{P}_{a}(\tau_z<\eta_A)-1] \cdot \mathbb{E}_{a} \setsquared*{\eta_a^1 ;\eta_a^1 < \tau_z} + \frac{\mathbb{P}_{a}(\tau_z<\eta_a^1)}{\mathbb{P}_a(\tau_z< \eta_a^1)} \mathbb{E}_a \setsquared*{\eta_a^1 ;\tau_z < \eta_a^1} \\
                                                          &=\left(\frac{1}{\mathbb{P}_a(\tau_z < \eta_a^1)}-1\right) \mathbb{E}_a \setsquared*{\eta_a^1 ;\eta_a^1< \tau_z} + \frac{\mathbb{P}_{a}(\tau_z<\eta_a^1)}{\mathbb{P}_a(\tau_z< \eta_a^1)} \mathbb{E} \setsquared*{\eta_a^1  ;\tau_z < \eta_a^1} \\
                                                          &=\frac{1}{\mathbb{P}_a (\tau_z< \eta_a^1)} \left[\mathbb{P}_a(\eta_a^1<\tau_z) \mathbb{E}_a \setsquared*{\eta_a^1 ;\eta_a^1 < \tau_z}+ \mathbb{P}_a(\tau_z<\eta_a^1)  \mathbb{E}_a \setsquared*{\eta_a^1 ;\tau_z < \eta_a}\right] \\
                                                          &=\frac{1}{\mathbb{P}_a(\tau_z < \eta_a^1} \mathbb{E}_a[\eta_a^1] \\
                                                          &= \frac{2 \sum_e c(e)}{c(a)} / \frac{c_{\mathrm{eff}(a,z)}}{c(a)} \\
                                                          &=2 \frac{\sum_e c(e)}{c_{\mathrm{eff}}(a,z)} \\
                                                          &=2 R_{\mathrm{eff}(a,z)} \sum_e c(e)
        \end{align*}
        
    \end{enumerate}

\end{proof}



\begin{exer}
    We have that 
  \[\mathbb{P}_x(\tau_a< \tau_z) \leq \frac{c_{\mathrm{eff}}(x,a)}{c_{\mathrm{eff}}(x,z)}\]
\end{exer}

To make use of these theorem, we need to be able to estimate (or calculate) effective resistance/conductance. In some examples we are capable of calculating effective resistances.

\begin{fact}
    We have the following: 
    \begin{enumerate}[1)]
      \item in $d=1$, \(R_{\mathrm{eff}}(0,n)=n\)
    \item in $d=2$, \(R_{\mathrm{eff}} \left((0,0),(n,n)\right)=\mathcal{O}(\ln n)\)
    \item in $d=3$, \(R_{\mathrm{eff}} \left((0,0,0),(n,n,n)\right)=\mathcal{O}(n) \)
    \end{enumerate}
Thus, we have 
\begin{align*}
  \mathbb{E}_{a,0}[\tau_{n,n}] &= \frac{1}{2} \left(\mathbb{E}_{a,0}[\tau_{n,n}]+ \mathbb{E}_{n,n}[\tau_{0,0}]\right) \\
                               &=\frac{1}{2} 2 R_{\mathrm{eff}} \left((0,0),(n,n)\right) \sum_e c(e) \\
                               &=\mathcal{O}(n^2 \cdot \ln n)
\end{align*} 

\end{fact}


\begin{defn}[Associated Hilbert space]
    Let \(G=(V,E)\) be a graph of bounded degree, i.e. \(\sup_{v\in V} \operatorname{deg}v<\infty \). We define the associated Hilbert space 
    \[\ell^2(V) := \set*{f: V \to \mathbb{R}; \sum_v f^2(v) < \infty }\]
with the scalar product 
\[\left\langle f, g \right\rangle =  \sum_v f(v)\cdot g(v) \quad \text{for \(f,g \in \ell^2(V).\)}\]
For \(e=(u,v)\), we define \(\widecheck{e}=u, \widehat{e}=v\) and \(-e=(v,u)\). We define the associated Hilbert space 
\[\ell^2_{-}(E):= \set*{\theta: E \to \mathbb{R}; \sum_e \theta(e)< \infty,\, \theta(-e)=-\theta(e) }\]
with the scalar product
\[ \left\langle \theta, \eta \right\rangle = \frac{1}{2} \sum_e \theta(e) \cdot \eta(e)\]

\end{defn}

\begin{defn}[Boundary and coboundary operator]
We define the \emph{coboundary operator} as 
\[d: \ell^2(V) \to \ell^2_{-}(E),\, df(e)=f(\widecheck{e})-f(\widehat{e}) \quad\text{for \(e\in E\).}\]
and the \emph{boundary operator} as 
\[d^*: \ell^2_{-}(E) \to \ell^2(V),\, d^*\theta(v)=\sum_{e: \widecheck{e}=v} \theta(e) \quad\text{for \(v\in V\).} \]
   

\end{defn}

\begin{exer}[]
    Show that $d,d^*$ are well-defined.
\end{exer}

\begin{lem}[]
    \(d,d^*\) are adjoint linear maps, i.e. for all \(f \in \ell^2(V), \theta \in \ell^2_{-}(E)\), we have \( \left\langle \theta, df \right\rangle = \left\langle d^*\theta, f \right\rangle  \).
\end{lem}

\begin{proof}
    We show the proof in two steps:
    \begin{enumerate}[]
      \item \(- \sum_{e: \widehat{e}=v}\theta(e) = \sum_{e: \widehat{e}=v} \theta(-e) = \sum_{e: \widecheck{e}=v} \theta(e) = d^*\theta(v)\).
      \item By definition of the scalar product, we have
        \begin{align*}
          \left\langle \theta,df \right\rangle &= \frac{1}{2}\sum_e \theta(e) \cdot \left(f( \widecheck{e})- f( \widehat{e}) \right) \\
                                               &=\frac{1}{2}\sum_e \theta(e) f( \widecheck{e}) - \frac{1}{2} \sum_e \theta(e) f( \widehat{e}) \\
                                               &=\frac{1}{2}\sum_v f(v) \sum_{e: \widecheck{e}=v}\theta(e) - \frac{1}{2} \sum_v f(v)\sum_{e: \widehat{e}=v} \theta(v) \\
                                               &\overset{\mathclap{1.}}{=} \sum_v f(v)\cdot d^*\theta(v) \\
                                               &= \left\langle d^*\theta, f \right\rangle 
        \end{align*}
    \end{enumerate}
    
\end{proof}


\begin{remark}[]
    We have the following results:
    \begin{itemize}
      \item Ohm's law:  \(dU(e) = i(e)\cdot r_{e}\);
      \item Kirchhoff's node law: \(d^*i(v) = 0\) for \(v \in V \setminus (A \cup Z)\).
    \end{itemize}
    
\end{remark}

\begin{defn}[Flow and strength]
   \(\theta\) is called a \emph{flow} ffrom \(A\) to \(Z\) if 
   \begin{enumerate}[1)]
     \item \(d^*\theta \geq 0\) on \(A\);
     \item \(d^*\theta =0\) on \(V \setminus (A\cup Z)\); 
     \item \(d^*\theta\leq 0\) on \(Z\).
   \end{enumerate}
   We define the \emph{strength} of a flow \(\theta\) as \( \operatorname{strength}(\theta) = \sum_{a\in A} d^*\theta(a)  \).
\end{defn}

\begin{lem}[Flow conversion]
    Let \(G\) be a finite graph and \(theta\) be a flow from \(A\) to \(Z\) with \(A,Z \subseteq  V\) and \(A \cap Z = \emptyset \). Then, 
    \[\sum_{a \in A} d^* \theta(a) = - \sum_{z\in Z} d^*\theta(z)\]
    Furthermore, if \(f:V \to \mathbb{R}\) such that \(f\vert_A = \alpha \) and \(f\vert_Z=\zeta\), then \( \left\langle \theta, df \right\rangle = \operatorname{strength}(\theta)(\alpha-\zeta)\).
\end{lem}


\begin{proof}
   We show the proof in two steps:
  \begin{enumerate}[]
    \item We have by defintion of the scalar product
      \begin{align*}
        \sum_{a\in A} d^* \theta(a) + \sum_{v\in V \setminus (A\cap Z)} d^*\theta(v) + \sum_{z\in Z} d^*\theta(z) &= \left\langle d^*\theta, \mathbbm{1}_V \right\rangle \\
                                                                                                                  &= \left\langle \theta, d \mathbbm{1}_V \right\rangle \\
                                                                                                                  &=0
      \end{align*}
    \item To show the second statement, notice that 
      \begin{align*}
        \left\langle \theta, df \right\rangle &= \left\langle d^*\theta, f \right\rangle \\
                                              &=\sum_{v\in V} d^*\theta(v)\cdot f(v) \\ 
                                              &=\sum_{a\in A} d^*\theta(a)\cdot f(a) + \sum_{z\in Z} d^*\theta(z)\cdot f(z) \\
                                              &\overset{\mathclap{1.}}{=} \operatorname{strength}(\theta)(\alpha-\zeta)
      \end{align*}
      
  \end{enumerate}
  
\end{proof}

\begin{defn}[Energy]
    For antisymmetric fucntions \(\theta, \eta\), we define the scalar product
    \[ \left\langle \theta, \eta \right\rangle_r = \frac{1}{2}\sum_{e}\theta(e)\cdot \eta(e)\cdot r_{e}\]
    We define the \emph{energy} of an antisymmetric function \(\theta\) as \(\mathcal{E}(\theta)=\norm{\theta}_{r}^2 = \frac{1}{2}\sum_{e}\theta(e)\cdot r_{e}\).
\end{defn}


\begin{lem}[]
    Let \(i: E \to \mathbb{R}\) be a unit current flow from \(A\) to \(Z\) such that the voltage \(\mathcal{U}\) satisfies \(\mathcal{U}\vert_A= \mathcal{U}_A\) and \(\mathcal{U}\vert_Z=\mathcal{U}_Z\). Then, \(\mathcal{E}(i)=\mathcal{U}_A- \mathcal{U}_Z= R_{\mathrm{eff}}(A \leftrightarrow Z)\). 
\end{lem}

\begin{proof}
    By Ohm's law, we have 
    \begin{align*}
      \mathcal{E}(i) &= \left\langle i,i \right\rangle_r \\
                     &= \left\langle i,ri \right\rangle \\
                     &= \left\langle i,dU \right\rangle \\
                     &= \left(\mathcal{U}_A- \mathcal{U}_Z\right) \underbrace{\operatorname{strength}(i)}_{=1} \\
                     &=\mathcal{U}_A-\mathcal{U}_Z
    \end{align*}
    Since all vertices in \(A\) have the same voltage, we can identify them as one point \(a\). Then,
    \begin{align*}
      c_{\mathrm{eff}}(a \leftrightarrow Z) &= \sum_{x\neq a} \theta(a,x) \\
                                            &= \sum_{x\neq a} \frac{i(a,x)}{\mathcal{U}_A-\mathcal{U}_Z} \\
                                            &= \frac{1}{\mathcal{U}_A-\mathcal{U}_Z}
    \end{align*}
    This is equivalent to \(R_{\mathrm{eff}}=\mathcal{U}_A \cdot \mathcal{U}_Z\).    
\end{proof}

\begin{lem}[]
    Let \(i: E \to \mathbb{R}\) be antisymmetric satisfying Kirchhoff's cycle law. Suppose \(i\) satisfies Kirchhoff's node law on \(W \subseteq V\). Then, there exists a function (voltage) \(\mathcal{U}: V \to \mathbb{R}\), such that \(U\) is harmonic on \(W\) and \(i\) is the current associated with \(\mathcal{U}\). The voltage is unique up to addition. 
\end{lem}

\begin{proof}
    We show the proof in two steps:
    \begin{enumerate}[]
      \item Existence: Let \(v_0\in V\) and set \(\mathcal{U}(v_0)=0\). For \(u\in V\), let \((v_0,\dots, v_N=u)\) be a path from \(v_0\) to \(u\). We define \[\mathcal{U}(u)=\sum_{n=1}^{N}r_{\{v_{n-1},v_{n}\}}i(v_{n}, v_{n-1}) \]
        Let \((w_0=v_0, \dots, w_m=v_n)\) be a second path, then \((v_0, \dots, v_n=w_m, \dots, w_0=v_0)\) is a cycle, Thus, 
        \[\sum_{n=1}^{N} r_{\{v_{n-1},v_n\}} i(v_{n},v_{n-1})=0 \]
        Thus, \(\mathcal{U}\) is well-defined. For \(\{u,v\} \in E\), we can join the edge to the path \[\mathcal{U}(v) = \mathcal{U}+r_{\{u,v\}}i(v,u)\]
        Then, we have \(i(v,u) = \frac{1}{r_{\{u,v\}}} \left(\mathcal{U}(v)-\mathcal{U}(u)\right)\). Then, the current \(i\) is associated to \(\mathcal{U}\). Harmonicity on \(W\) follows from Kirchhoff's node law.
      \item Uniqueness: For a given \(\mathcal{U}(v_0)\), we can define \(\mathcal{U}(u)\) inductively by Ohm's law. 
    \end{enumerate}
    
\end{proof}


\subsubsection{Thomson's principle and corollaries}

\begin{thm}[Thomson's principle]
    It holds 
    \[R_{\mathrm{eff}}(a,z) = \inf_{} \set*{\mathcal{E}(F); F \text{ unit flow from \(a\) to \(z\)}}\]
    Furthermore, the infimum is attained at the unit current flow.
\end{thm}


\begin{corl}[]
    Let \(G_1=(V,E_1,c_1)\) and \(G_2=(V,E_2,c_2)\), \(a\neq z \in V\). Assume \(E_1 \subseteq E_2\) and for all \(e \in  E_1\), we have \(c_2(e) \geq c_1(e)\). Then,
    \begin{align*}
      C_{\mathrm{eff}}^{G_1}(a,z)&\leq C_{\mathrm{eff}}^{G_2}(a,z)\\
      \mathbb{P}^{G_2}(\tau_z<\eta_a) & \geq \mathbb{P}^{G_2}(\tau <\eta_a).
    \end{align*}
\end{corl}


\begin{proof}
    Let \(I\) be the unit current flow from \(a\) to \(z\) in \(G_1\). Then,
    \begin{align*}
      R_{\mathrm{eff}}^{G_2}&= \inf_{\mathclap{F}} \mathcal{E}^{G_2}(F) \\
                            & \leq \mathcal{E}^{G_2}(I) \\
                            & = \sum_{e\in E_2} \frac{\abs{I(e)} ^2}{c_2(e)} \\
                            & \overset{(a)}{=}\sum_{e \in E_1} \frac{\abs{I(e)} ^2}{c_2(e)} \\
                            & \leq \sum_{e \in E_1} \frac{\abs{I(e)} ^2}{c_2(e)} \\
                            & = \mathcal{E}^{G_1}(I) \\
                            & = R_{\mathrm{eff}}^{G_1}(a,z)
    \end{align*}
Hence, \(C_{\mathrm{eff}}^{G_1}(a,z) \leq C_{\mathrm{eff}}^{G_2}(a,z)\). The second result follows from noting that
\begin{align*}
  \mathbb{P}^{G_2}(\tau_z <\eta_a) &= \frac{C_{\mathrm{eff}}^{G_2}(a,z)}{c^{G_2}(a)} \\
                                   &\geq \frac{C_{\mathrm{eff}}^{G_1}(a,z)}{c^{G_1}(a)} \\
                                   &= \mathbb{P}^{G_2}(\tau_z < \eta_a)
\end{align*}

\end{proof}


\begin{corl}[Monotonicity of effective conductance]
    Let \(G=(V,E,c) \) be a network, \(a\in V\), \(\emptyset \neq Z_1 \subseteq Z_2 \subseteq V \setminus \{a \} \). Then, \(C_{\mathrm{eff}}(a,Z_1) \leq C_{\mathrm{eff}}(a,Z_2)\).
\end{corl}



\begin{defn}[Exhaustion]
    Let \(G=(V,E,c)\) be an infinite, locally finite, connected graph (including \(\mathbb{Z}^d\), regular trees, Cayley graphs). A sequence \((V_n)_n \) of sets of vertices is called an \emph{exhaustion} of the graph if 
    \begin{enumerate}[1)]
      \item for all \(n \in \mathbb{N}\), \(\abs{V_n} < \infty \);
      \item for all \(n \in  \mathbb{N}\), \(V_n \subseteq V_{n+1} \subseteq V\);
      \item \( \bigcup_{n=1}^{\infty} V_n = V\).
    \end{enumerate}
    We define \(G_n := G / (V \setminus C_n)\) as the graph with \(V \setminus V_n \) reduced to a single vertex.
\end{defn}


\begin{defn}[Effective conductance to infinity]
  Let \(a \in V\). We define the \emph{effective conductance} between \(a\) and \(\infty \) as \[C_{\mathrm{eff}}(a,\infty) = \lim_{n \to \infty} C_{\mathrm{eff}}^{G_n}(a, V \setminus V_n).\]
\end{defn}


\begin{fact}[Well-definedness of effective conductance to infinity]
  The conductance \(C_{\mathrm{eff}}(a,\infty )= \lim_{n \to \infty} C_{\mathrm{eff}}^{G_n}(a,V \setminus V_n)\) is well-defined. 
\end{fact}

\begin{proof}
    We have to show existence of the limit and independence of the choice of exhaustion.
  \begin{enumerate}[]
    \item Existence: By monotonicity of effective conductance, \(C_{\mathrm{eff}}(a,G \setminus V_n) \geq C_{\mathrm{eff}}(a,G \setminus V_{n+1)}\). Hence \( \left(C_{\mathrm{eff}}(a,G \setminus \right)\) is monotonically decreasing. It is also bounded from below, hence convergent.
    \item Let \((V_n)_n\) and \((W_n)_n\) be two exhaustions. Then, for each \(n\) there is some \(m\) such that \(V_n \subseteq W_m\) and vice-versa. Thus,
      \begin{align*}
        \lim_{m \to \infty} C_{\mathrm{eff}}(a,G \setminus W_m) &\leq C_{\mathrm{eff}}(a,G \setminus  V_n) \myxrightarrow[n\to\infty ]{} \lim_{n \to \infty} C_{\mathrm{eff}}(a, G \setminus V_n) \\
        \lim_{n \to \infty} C_{\mathrm{eff}}(a,G \setminus V_n) &\leq C_{\mathrm{eff}}(a, G \setminus W_m) \myxrightarrow[m\to\infty ]{} \lim_{m \to \infty} C_{\mathrm{eff}}(a, G \setminus W_m)
      \end{align*}
      Thus, we have equality.
  \end{enumerate}
  
\end{proof}

\begin{thm}[]
    The random walk starting at \(a\) is recurrent if and only if \(R_{\mathrm{eff}}(a, \infty ) = \infty \) (i.e. \(C_{\mathrm{eff}}(a, \infty )=0\)).
\end{thm}

\begin{proof}
    Let \((V_n)_n\) be an exhaustion. Then,
    \begin{align*}
      \mathbb{P}(\eta_a < \infty ) &= \lim_{n \to \infty} \mathbb{P}(\eta< \tau_{G \setminus V_n)} \\
                                   &=1-\lim_{n \to \infty} \mathbb{P}(\eta_a > \tau_{G \setminus V_n}) \\
                                   &=1 - \frac{1}{c(a)}\lim_{n \to \infty} C_{\mathrm{eff}}(a, G \setminus V_n) \\
                                   &=1- \frac{C_{\mathrm{eff}}(a, \infty )}{\underbrace{c(a)}_{\in (0,\infty )}}
    \end{align*}
  \(R_{\mathrm{eff}}(a, \infty ) = \infty \)  is equivalent to \(C_{\mathrm{eff}}(a, \infty )=0\). By our calculations, this is equivalent to \(\mathbb{P}(\eta_a < \infty )=1\).
\end{proof}

\begin{thm}[Thomson's principle for infinite networks]
    A \emph{unit flow} from \(a\) to \(\infty \) in \(G\) is an antisymmetric edge function \(F\) such that for all \(u \in  V\), we have 
    \[\sum_{v \neq u}^{} F(u,v)= 
    \begin{cases}
      1, & x=a \\
      0, & x \neq a 
    \end{cases}
    \]
    Then, \[R_{\mathrm{eff}}(a, \infty ) =\inf_{} \set*{\mathcal{E}(F); F \text{ is unit flow from \(a\) to \(\infty \)}} \quad \txt{for }\mathcal{E}(F):= \sum_{e}^{} \frac{\abs{F(e)} ^2}{c(e)}. \]
\end{thm}


\begin{remark}[]
    In order to prove that a graph (or network) is transient, all we need to find is a flow of finite energy
\end{remark}


\begin{exm}[Binary tree]
    What is \(\mathcal{E}(F)\) of a binary tree with three edges at the origin? At level \(n\), we have \(3 \cdot 2^n\) edges, each carries a flow of \((3 \cdot 2^n)^{-1}\). Thus, \(\mathcal{E}(F)= \sum_{n=0}^{\infty} 3 \cdot 2^n \cdot {3 \cdot 2^n}^{-2} < \infty \).
\end{exm}

From Thomson's principle we get monotonicity: If \(G\) is recurrent and \(G'\) is a subgraph of \(G\), then \(G'\) is recurrent as well. The argument is as follows. Let \(F\) be a flow on \(G'\), then \(F\) is also a flow on \(G\) and \(\mathcal{E}^{G'}(F) = \mathcal{E}^{G}(F)= \infty \) since \(G\) is recurrent. Thus, \(G'\) is recurrent. As a result we find a way to prove transience. Namely, we have to find a flow with finite energy. We now find a criterion for recurrence.


\begin{defn}[Cutset]
  Let \(G=(V,E,c) \) be an infinite network and let \(a \in  V\). A set \(\Pi \subseteq E\) is called a \emph{cutset} if every infinity simple path starting from \(a\) has non-empty intersection with \(\Pi\). We define the conductance of \(\Pi\) as \(\sum_{e \in \Pi}c(e)\).
\end{defn}


\begin{thm}[Nash-Williams]
    Let \((\Pi_n)_n\) be a sequence of disjoint cutsets, then \(R_{\mathrm{eff}}(a,\infty) \leq \sum_{n=1}^{\infty} \frac{1}{c(\Pi_n)}\).
\end{thm}

\begin{proof}
    Let \(F\) be a unit flow from \(a\) to \(\infty \). For all \(n\), \(\sum_{e \in \Pi_n} \abs{F(e)}  \leq 1\), since the amount of flow going through the cutset is at least 1). Thus,
    \begin{align*}
      \mathcal{E}(F) &= \frac{1}{2} \sum_{e \in E}^{} \frac{\abs{F(e)} ^2}{c(e)} \\
                     &= \sum_{n=1}^{\infty} \left(\sum_{e \in \Pi_n}^{} \frac{\abs{F(e)} ^2}{c(e)}\right) \\
                     &\overset{(1)}{\geq} \sum_{n=1}^{\infty} \frac{1}{\sum_{e \in \Pi_n }^{} c(e)} \\
                     &= \sum_{n=1}^{\infty}  \frac{1}{c(\Pi_n)}.
    \end{align*}
(1) follows from Sedrakyan's lemma.  
\end{proof}

\begin{lem}[Sedrakyan's lemma]
    Let \(\sum_{n=1}^{N} x_n \geq 1\) and \(c_1, \dots, c_N >0\). Then
    \[\sum_{n=1}^{N} \frac{x_n^2}{c_n} \geq \frac{1}{\sum_{n=1}^{N} c_n}.\]
\end{lem}


\begin{thm}[]
    \(\mathbb{Z}^3\) is transient.
\end{thm}

\begin{proof}
    We provide a flow of finite energy by Y. Peres. This is done in the following steps:
    \begin{enumerate}[1.]
      \item Define the dual of \(\mathbb{Z}^3\). For every edge \(e \in E(\mathbb{Z}^3)\), take the dual \(e'\) to the plaquette perpendicualr to \(e\). 
      \item Consider a sphere with surface area of 1 around the origin.
      \item The flow is directed away from the origin. The intensity of the flow is the area of the projection of the plaquette on the sphere.
    \end{enumerate}
    We have to show that this in fact defines a flow (i) and find a bound of \(\mathcal{E}(F)\) (ii). 
    \begin{enumerate}[(i)]
      \item We need to show that for every \(x \neq 0 =: a\), the amount going in is the same as the amount going out.
      \item \(\abs{F(e)} = \text{[size of projection]}\). Each axis of the projection is at most \(\frac{1}{\abs{e} }\). Thus, the area of the projection is at most \(\frac{1}{\abs{e}^2} \). Hence, 
        \begin{align*}
          \mathcal{E}(F) &\leq \sum_{e \in E(\mathbb{Z}^3)} \left(\frac{1}{\abs{e} ^2}\right)^2 \\
            &\leq\sum_{n=1}^{\infty} \left(\frac{1}{n^2}\right)^2  \operatorname{card}\set*{e; n \leq \abs{e} \leq n+1}\\
            &\leq c \sum_{n=1}^{\infty} \frac{1}{n^2} < \infty.
        \end{align*}
        
    \end{enumerate}
    
\end{proof}



\subsection{Spherically symmetric trees}

\begin{defn}[Rooted tree]
    
\end{defn}

\begin{defn}[Spherically symmetric tree]
    A rooted tree \((T, \rho) \) is called \emph{spherically symmetric} if for all \(u,v \in T\), we have \[d(v,\rho)= d(u,\rho) \implies \operatorname{deg}u= \operatorname{deg}v.\]
    If \((T, \rho\) is such a spherically tree. We define \[f(n):=[\text{outwards degree of vertices at distance \(n\) from \(\rho\)}]\]. Then, \((T,\rho)\) is determined by \(f(n))_n\) up to an isometry (rotation). We further set \(g(N):= \sum_{n=1}^{N} f(n)\) as the number of vertices at distance at distance \(n\) from \(\rho\).
\end{defn}


\begin{thm}[]
  Let \(T\) be a spherically symmetric tree. Then, the following statements are equivalent:
  \begin{enumerate}[1)]
    \item \(T\) is recurrent;
    \item \(\sum_{n=1}^{\infty} \frac{1}{g(n)}=\infty \).
  \end{enumerate}
  Notice, that \([2) \implies 1]\) even if \(T \) is a general graph instead of a spherically symmetric tree. The converse implication fails.
\end{thm}

\begin{proof}
    \begin{enumerate}[]
      \item \([2) \implies 1)]\). Define \(\Pi_n= \set*{(u,v); d(v,\rho)=n-1,\, d(u,\rho)=n}\). Then, \((\Pi_n)_n\) is a sequence of disjoint cutsets, and setting \(c(\Pi_n)=g(n)\) yields \(\sum_{n=1}^{\infty} \frac{1}{c(\Pi_n)}= \infty \). Thus \(T\) is recurrent.
      \item Assume to the contrary that \(\sum_{n=1}^{\infty} \frac{1}{g(n)}\). We define a flow \(F\) as follows. Let \(e=(u,v)\) such that \(d(u,\rho)=d(v,\rho)-1\) (i.e. \(v\) is parent of \(u\)). We then set \(\abs{F(u,v)}=\frac{1}{g(n)}\) for \(n=d(v,\rho)\) (Notice, that this defines a flow only on a spherically symmetric tree!). We then obtain
        \begin{align*}
          \mathcal{E}(F) &= \frac{1}{2}\sum_e \abs{F(e)} ^2 \\
                         &=\frac{1}{2}\sum_{n=1}^{\infty} \sum_{{u:d(u,\rho)=n}}^{} \abs{F(\underbrace{u'}_{\text{parent of \(u\)}},u)}^2 \\
                         &= \frac{1}{2} \sum_{n=1}^{\infty} \underbrace{g(n)}_{\text{number of vertices}} \underbrace{\left(\frac{1}{g(n)}\right)^2}_{\text{intensity}} \\
                         &= \infty 
        \end{align*}
        Thus, we have transience. 
    \end{enumerate}
    
\end{proof}

We now want to deal with random conductances on fixed graphs such as \(\mathbb{Z}\) or \(\mathbb{Z}^2\). We assume the following restrictions:
\begin{enumerate}[1)]
  \item random conductances are in \((0, \infty)\);
  \item the distribution of conductances is translation invariant, i.e. for all \(x \in \mathbb{Z}\; (\mathbb{Z}^2)\), we have  \((c(e))_e =_d (c(e+x))_e\).
\end{enumerate}
We would like to know whether we can produce a transient network by choosing random conductances for the recurrent graph.
\subsubsection{Random network is one-dimensional lattice}
\begin{thm}[]
    \(\mathbb{Z}\) as a random network is always a recurrent.
\end{thm}

\begin{proof}
  Fix \(\epsilon>0\). We show that \(\mathbb{P}(\text{Network is recurrent})\geq 1-2 \epsilon.\) Take \(M\) usch that \(\mathbb{P}(c(e) >M)< \epsilon\). Then we have that 
  \begin{align*}
    \mathbb{P}(\text{There are infinitely many \(n\geq 0\) such that \(\underbrace{c(n,n+1) \leq M}_{A_n:=}\)} &= \mathbb{P} \left(\bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty } A_k\right) \\
                                                                                                         &\overset{=}{\text{I}}\lim_{n \to \infty} \mathbb{P} \left(\bigcup_{k=n}^{\infty }\right) \\
                                                                                                         &\geq\varliminf_{n \to \infty} \mathbb{P}(A_k) \\
                                                                                                         &= \geq 1- \epsilon
  \end{align*}
  (I) holds since the intersection contains decreasing sets. It follows that the probability that there are infinitely many \(n\geq 0\) with \(c(n,n+1) \leq M\) and infinitely many \(n \leq 0\) with \(c(n,n-1) \leq M\) is at least \(1- 2\epsilon\). Thus we can find infinitely many disjoint cutsets with individual conductance at most \(2M\).

\end{proof}

\subsubsection{Random network is two-dimensional lattice}
The two-dimensional case is more delicate and depends on further circumstances. 

\begin{thm}[]
    Consider \(\mathbb{Z}^2\) as a random network. Then, the following statements hold:
    \begin{enumerate}[1)]
      \item If \(\mathbb{E} \left[c(e)\right] < \infty \) for horizontal and vertical edges \(e\), the network is recurrent;
      \item If conductances are independent, the network is recurrent;
      \item There exists a transient system of random conductances on \(\mathbb{Z}^2\).
    \end{enumerate}
    
\end{thm}

\begin{proof}
    We show the result in a few steps:
    \begin{enumerate}[1.]
      \item Assign 1 to every edge;
      \item For every vertex sample \(V_x, H_x\) (vertical, horizontal) iid, we set 
        \[
        \begin{cases}
          \mathbb{P} \left(V_x=n\right)=3^{-n}, &  n \geq 1 \\
          \mathbb{P} \left(V_x=0\right)= 1- \sum_{n=1}^{\infty} 3^{-n} 
        \end{cases}
        \]
        \begin{description}
          \item For every \(x\), if \(V_x \geq 1\), then add \(4^{V_x}\) to the \(2^{V_x}\) above \(x\);
          \item For every \(x\), if \(H_x \geq 1\), then add \(4^{H_x}\) to the \(2^{H_x}\) right to \(x\).
        \end{description}
    \end{enumerate}
   By Borel-Cantelli, each edge will have infinitely many contributions.  
\end{proof}

